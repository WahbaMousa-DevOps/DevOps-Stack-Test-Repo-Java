// Purpose: Build, test, scan, and push a Java Gradle-based Dockerized app using the java agent.
// Enhanced with:
//   1. Git metadata capture - Comprehensive tracking of Git history and changes
//   2. Failure error summaries - Detailed error reporting and classification
//   3. Comment clarity and traceability - Improved documentation throughout
//   4. Shared library readiness - Pipeline structured for easy extraction into shared libs
//
// Author: DevOps Pipeline Team
// Last Updated: 2025-05-11
// Version: 2.0.0

pipeline {
    parameters {
        booleanParam(name: 'TEST_MODE', defaultValue: false, description: 'Run pipeline in test mode (skips deployment)')
        booleanParam(name: 'SKIP_TESTS', defaultValue: false, description: 'Skip running tests')
        booleanParam(name: 'SKIP_SONAR', defaultValue: false, description: 'Skip SonarQube analysis')
        booleanParam(name: 'ALLOW_VULNERABLE_BUILD', defaultValue: false, description: 'Allow build to continue despite vulnerabilities')
    }
    agent { label 'java' }
    environment { // Environment variables available only during pipeline execution
        DOCKER_REGISTRY = 'docker.io'
        DOCKER_REPOSITORY = 'wahbamousa/java-sample-app'
        DOCKER_CREDENTIALS_ID = 'dockerhub-credentials'
        SONAR_PROJECT_KEY = 'DevOps-Stack-Test-Repo-Java'
        PIPELINE_START_TIME = "${System.currentTimeMillis()}"
        JAVA_OPTS = '-XX:+UseContainerSupport -XX:MaxRAMPercentage=75.0'
        GRADLE_OPTS = '-Dorg.gradle.daemon=false -Dorg.gradle.parallel=true -Dorg.gradle.jvmargs="-Xmx2048m -XX:+HeapDumpOnOutOfMemoryError"'
        
        // Environment-specific configurations
        DEPLOY_TARGET = [ // Dynamic environment mode from branch name
            'main': 'production',
            'staging': 'staging',
            'develop': 'development'
        ].get(env.BRANCH_NAME, 'development')
        
        // Resource limits based on environment
        MAX_MEMORY = "${DEPLOY_TARGET == 'production' ? '8192' : '4096'}"
        
        // Security scanning strictness by environment
        VULNERABILITY_SEVERITY = "${DEPLOY_TARGET == 'production' ? 'MEDIUM,HIGH,CRITICAL' : 'HIGH,CRITICAL'}"
        
        // Failure tracking for enhanced error reporting
        ERROR_TRACKING_DIR = "failure-reports"
    }
    options {
        timeout(time: 30, unit: 'MINUTES', activity: true) // Prevents builds from hanging forever
        disableConcurrentBuilds(abortPrevious: true) // Ensures only one build per branch is running
        buildDiscarder(logRotator(numToKeepStr: '10', artifactNumToKeepStr: '5')) // Keep 10 builds, 5 with artifacts
        timestamps() // Adds timestamps to every line of console output
        ansiColor('xterm') // Enables colored console logs
        lock('java-resources') // Prevents builds from racing over same tools/resources
        retry(2) // Retries pipeline if transient errors
        skipDefaultCheckout(true) // Custom checkout with depth/timeout controls
    }
    stages {
        /**
         * Purpose: Enhanced checkout with Git security scanning, metadata collection, and change analysis
         * Dependencies: git, git-secrets, gitleaks
         * Outputs: Git metadata, security scan results
         * Ticket: DEVOPS-321
         */
        stage('Enhanced Checkout') {
            steps {
                // Shallow clone for faster fetch
                checkout([
                    $class: 'GitSCM',
                    branches: scm.branches,
                    extensions: [
                        [$class: 'CloneOption', depth: 1, noTags: false, shallow: true, timeout: 5],
                        [$class: 'SubmoduleOption', disableSubmodules: false, recursiveSubmodules: true]
                    ],
                    userRemoteConfigs: scm.userRemoteConfigs
                ])

                // Secrets scanning with git-secrets and gitleaks
                sh '''
                    command -v git-secrets >/dev/null 2>&1 || { echo "git-secrets is required in CI. Aborting."; exit 1; }
                    git secrets --register-aws || true
                    git secrets --scan || (echo "CRITICAL: Secrets found in codebase!" && exit 1)

                    command -v gitleaks >/dev/null 2>&1 || { echo "gitleaks is required in CI. Aborting."; exit 1; }
                    gitleaks detect --source . --verbose || (echo "CRITICAL: Secrets found in codebase!" && exit 1)

                    find . -type f -size +10M | grep -v '.git/' > large_files.txt
                    if [ -s large_files.txt ]; then
                        echo "WARNING: Large files found in repository:"
                        cat large_files.txt
                    fi
                '''

                // Enhanced Git metadata capture
                script {
                    try {
                        // Basic Git info
                        def branchName = sh(script: 'git rev-parse --abbrev-ref HEAD', returnStdout: true).trim()
                        echo "Building branch: ${branchName}"

                        env.GIT_AUTHOR = sh(script: 'git log -1 --pretty=format:"%an <%ae>"', returnStdout: true).trim()
                        env.GIT_COMMIT_MSG = sh(script: 'git log -1 --pretty=format:"%s"', returnStdout: true).trim()
                        env.GIT_COMMIT_DATE = sh(script: 'git log -1 --pretty=format:"%ad" --date=iso', returnStdout: true).trim()
                        echo "Commit by: ${env.GIT_AUTHOR}"
                        
                        // Enhanced Git metadata for traceability
                        env.GIT_COMMIT_COUNT = sh(script: 'git rev-list --count HEAD', returnStdout: true).trim()
                        env.GIT_CONTRIBUTORS = sh(script: 'git shortlog -sne --all | wc -l', returnStdout: true).trim()
                        env.GIT_BRANCHES = sh(script: 'git branch -r | wc -l', returnStdout: true).trim()
                        env.GIT_CHANGED_FILES = sh(script: 'git diff --name-only HEAD~1..HEAD | wc -l', returnStdout: true).trim()
                        env.GIT_LATEST_TAG = sh(script: 'git describe --tags --abbrev=0 2>/dev/null || echo "no-tags"', returnStdout: true).trim()
                        
                        // Recent commit history
                        env.GIT_RECENT_COMMITS = sh(script: 'git log -n 5 --pretty=format:"%h|%an|%s" --no-merges', returnStdout: true).trim()
                        env.GIT_COMMITS_BY_AUTHOR = sh(script: 'git shortlog -sne HEAD~50..HEAD', returnStdout: true).trim()
                        env.GIT_IS_MERGE_COMMIT = sh(script: 'git rev-parse --verify HEAD^2 >/dev/null 2>&1 && echo "true" || echo "false"', returnStdout: true).trim()
                        
                        // File change impact analysis
                        env.GIT_CODE_CHANGES = sh(script: 'git diff --name-only HEAD~1..HEAD | grep -E "\\.(java|groovy|kt|scala)$" | wc -l', returnStdout: true).trim()
                        env.GIT_CONFIG_CHANGES = sh(script: 'git diff --name-only HEAD~1..HEAD | grep -E "\\.(xml|properties|yaml|yml|json)$" | wc -l', returnStdout: true).trim()
                        env.GIT_DOC_CHANGES = sh(script: 'git diff --name-only HEAD~1..HEAD | grep -E "\\.(md|txt|doc|docx)$" | wc -l', returnStdout: true).trim()
                        
                        // Store git metadata in structured format
                        def gitMetadata = [
                            'repository': env.GIT_URL ?: sh(script: 'git config --get remote.origin.url', returnStdout: true).trim(),
                            'branch': branchName,
                            'commit': env.GIT_COMMIT_HASH,
                            'author': env.GIT_AUTHOR,
                            'message': env.GIT_COMMIT_MSG,
                            'date': env.GIT_COMMIT_DATE,
                            'files_changed': env.GIT_CHANGED_FILES,
                            'commit_count': env.GIT_COMMIT_COUNT,
                            'contributors': env.GIT_CONTRIBUTORS,
                            'branches': env.GIT_BRANCHES,
                            'latest_tag': env.GIT_LATEST_TAG,
                            'recent_commits': env.GIT_RECENT_COMMITS,
                            'commits_by_author': env.GIT_COMMITS_BY_AUTHOR,
                            'is_merge_commit': env.GIT_IS_MERGE_COMMIT,
                            'code_changes': env.GIT_CODE_CHANGES,
                            'config_changes': env.GIT_CONFIG_CHANGES,
                            'doc_changes': env.GIT_DOC_CHANGES
                        ]
                        
                        // Create the directory if it doesn't exist
                        sh "mkdir -p reports"
                        
                        // Store as JSON for later analysis
                        writeJSON file: 'reports/git-metadata.json', json: gitMetadata, pretty: 4
                        archiveArtifacts artifacts: 'reports/git-metadata.json', fingerprint: true
                    } catch (e) {
                        echo "Failed to get Git metadata: ${e.message}"
                        collectFailureData('Checkout', 'Git Metadata', e.message)
                    }
                }
            }
            post {
                failure {
                    script {
                        collectFailureData('Checkout', 'Repository Checkout', 'Failed to checkout repository')
                    }
                }
            }
        }
        
        /**
         * Purpose: Set environment variables and build properties
         * Dependencies: git, gradle
         * Outputs: Environment variables for subsequent stages
         * Ticket: DEVOPS-322
         */
        stage('Set Variables') {
            steps {
                script {
                    env.GIT_COMMIT_HASH = sh(script: 'git rev-parse --short HEAD', returnStdout: true).trim()
                    env.DOCKER_IMAGE_TAG = "${GIT_COMMIT_HASH}-${BUILD_NUMBER}"
                    env.DOCKER_IMAGE_VERSION = "${DOCKER_REGISTRY}/${DOCKER_REPOSITORY}:${DOCKER_IMAGE_TAG}"
                    env.DOCKER_IMAGE_LATEST = "${DOCKER_REGISTRY}/${DOCKER_REPOSITORY}:latest"
                    
                    // Extract version from Gradle properties
                    try {
                        env.PROJECT_VERSION = sh(script: './gradlew properties -q | grep "version:" | awk \'{print $2}\'', returnStdout: true).trim()
                        if (!env.PROJECT_VERSION) {
                            env.PROJECT_VERSION = "1.0.0-b${BUILD_NUMBER}"
                            echo "No version found. Using fallback: ${env.PROJECT_VERSION}"
                        }
                    } catch (e) {
                        env.PROJECT_VERSION = "1.0.0-b${BUILD_NUMBER}"
                        echo "Error finding version: ${e.message}"
                        collectFailureData('Set Variables', 'Version Extraction', e.message)
                    }

                    def versionParts = env.PROJECT_VERSION.tokenize('.-+')
                    env.VERSION_MAJOR = versionParts.size() > 0 ? versionParts[0] : "1"
                    env.VERSION_MINOR = versionParts.size() > 1 ? versionParts[1] : "0"
                    env.VERSION_PATCH = versionParts.size() > 2 ? versionParts[2] : "0"
                    
                    env.APP_VERSION = "v${env.VERSION_MAJOR}.${env.VERSION_MINOR}.${env.VERSION_PATCH}-${env.DEPLOY_TARGET}-${env.GIT_COMMIT_HASH}"

                    // Intelligent project fingerprinting for cache key
                    env.CACHE_KEY = sh(script: '''
                        (
                            find . -name "build.gradle" -o -name "gradle.properties" -o -name "settings.gradle" | sort | xargs cat 2>/dev/null | md5sum | cut -d " " -f1
                            test -f gradle/wrapper/gradle-wrapper.properties && md5sum gradle/wrapper/gradle-wrapper.properties | cut -d " " -f1 || echo "no-wrapper-props"
                        ) | md5sum | cut -d " " -f1
                    ''', returnStdout: true).trim()

                    // Detect environment resources
                    env.JAVA_MAX_CPUS = sh(script: 'nproc || echo 4', returnStdout: true).trim()
                    env.MAX_MEMORY = sh(script: 'free -m | grep Mem | awk \'{print int($2 * 0.8)}\'', returnStdout: true).trim()

                    def branch = env.BRANCH_NAME ?: sh(script: 'git rev-parse --abbrev-ref HEAD', returnStdout: true).trim()
                    env.DEPLOY_ENVIRONMENT = branch == 'main' ? 'production' :
                                            branch == 'staging' ? 'staging' :
                                            branch.startsWith('release/') ? 'uat' : 'development'

                    echo """
                    ===========================================
                    BUILD METADATA:
                    - Version: ${env.PROJECT_VERSION}
                    - Commit: ${env.GIT_COMMIT_HASH}
                    - Author: ${env.GIT_AUTHOR ?: 'Unknown'}
                    - Environment: ${env.DEPLOY_ENVIRONMENT}
                    - Cache Key: ${env.CACHE_KEY}
                    - Git Changes: 
                      * Code: ${env.GIT_CODE_CHANGES ?: 'Unknown'} files
                      * Config: ${env.GIT_CONFIG_CHANGES ?: 'Unknown'} files
                      * Docs: ${env.GIT_DOC_CHANGES ?: 'Unknown'} files
                    ===========================================
                    """
                    
                    // Create error tracking directory
                    sh "mkdir -p ${ERROR_TRACKING_DIR}"
                }
            }
            post {
                failure {
                    script {
                        collectFailureData('Set Variables', 'Environment Setup', 'Failed to set up environment variables')
                    }
                }
            }
        }

        /**
         * Purpose: Create comprehensive audit records for compliance and traceability
         * Dependencies: None
         * Outputs: JSON audit record
         * Ticket: DEVOPS-323
         */
        stage('Audit Setup') {
            steps {
                script {
                    // Create audit record
                    def auditData = [
                        'pipeline_id': env.BUILD_TAG,
                        'started_by': currentBuild.getBuildCauses()[0].shortDescription,
                        'branch': env.BRANCH_NAME,
                        'commit': env.GIT_COMMIT_HASH,
                        'start_time': new Date().format("yyyy-MM-dd'T'HH:mm:ss.SSSZ"),
                        'environment': env.DEPLOY_ENVIRONMENT,
                        'git_author': env.GIT_AUTHOR,
                        'commit_message': env.GIT_COMMIT_MSG,
                        'commit_date': env.GIT_COMMIT_DATE,
                        'project_version': env.PROJECT_VERSION,
                        'parameters': [
                            'test_mode': params.TEST_MODE,
                            'skip_tests': params.SKIP_TESTS,
                            'skip_sonar': params.SKIP_SONAR,
                            'allow_vulnerable_build': params.ALLOW_VULNERABLE_BUILD
                        ]
                    ]
                    
                    writeJSON file: 'pipeline-audit.json', json: auditData, pretty: 4
                }
            }
            post {
                always {
                    script {
                        // Update audit record with completion status
                        def auditData = readJSON file: 'pipeline-audit.json'
                        auditData.put('end_time', new Date().format("yyyy-MM-dd'T'HH:mm:ss.SSSZ"))
                        auditData.put('status', currentBuild.result)
                        auditData.put('duration_ms', System.currentTimeMillis() - env.PIPELINE_START_TIME.toLong())
                        
                        // Add failure reports if they exist
                        if (fileExists(ERROR_TRACKING_DIR)) {
                            def failureFiles = findFiles(glob: "${ERROR_TRACKING_DIR}/*.json")
                            if (failureFiles.length > 0) {
                                def failures = []
                                failureFiles.each { file ->
                                    failures.add(readJSON file: file.path)
                                }
                                auditData.put('failures', failures)
                            }
                        }
                        
                        writeJSON file: 'pipeline-audit.json', json: auditData, pretty: 4
                        archiveArtifacts artifacts: 'pipeline-audit.json', fingerprint: true
                    }
                }
                failure {
                    script {
                        collectFailureData('Audit Setup', 'Audit Configuration', 'Failed to set up audit trail')
                    }
                }
            }
        }

        /**
         * Purpose: Analyze project dependencies for vulnerabilities and outdated packages
         * Dependencies: gradle, dependency-check, OWASP tools
         * Outputs: Dependency reports and vulnerability analysis
         * Ticket: DEVOPS-324
         */
        stage('Dependency Audit') {
            steps {
                sh '''
                    # Generate dependency tree
                    ./gradlew dependencies > dependency-tree.txt
                    
                    # Check for vulnerable dependencies
                    if command -v dependency-check >/dev/null 2>&1; then
                        dependency-check --project "Java App" --scan . --out dependency-check-report.html || true
                    else
                        ./gradlew dependencyCheckAnalyze || echo "DependencyCheck failed, but continuing..."
                    fi
                    
                    # Check for outdated dependencies
                    ./gradlew dependencyUpdates -Drevision=release > outdated-dependencies.txt || true
                    
                    # Check for license issues
                    ./gradlew licenseReport || echo "License report generation failed, but continuing..."
                    
                    # OWASP Dependency Check (if gradle plugin is available)
                    if grep -q "org.owasp.dependencycheck" build.gradle || grep -q "org.owasp.dependencycheck" *.gradle; then
                        ./gradlew dependencyCheckAnalyze || echo "OWASP dependency check failed, but continuing..."
                    fi
                    
                    if [ -f "build/reports/dependency-check-report.html" ]; then
                        VULN_COUNT=$(grep -c "One or more dependencies were identified with known vulnerabilities" build/reports/dependency-check-report.html || echo "0")
                        if [ "$VULN_COUNT" -gt "0" ]; then
                            echo "WARNING: Vulnerabilities found in dependencies!"
                            
                            if [ "$DEPLOY_ENVIRONMENT" = "production" ]; then
                                if [ ! -f .vuln-exceptions ]; then
                                    echo "ERROR: Vulnerabilities found in production and no exception file present."
                                    exit 1
                                fi
                            else
                                if [ "${ALLOW_VULNERABLE_BUILD}" != "true" ]; then
                                    echo "ERROR: Vulnerabilities found and override not allowed (ALLOW_VULNERABLE_BUILD=false)."
                                    exit 1
                                fi
                            fi
                        fi
                    fi
                    
                    # Enhanced dependency analysis - create JSON summary
                    DIRECT_DEPS=$(grep -c "--- " dependency-tree.txt || echo "0")
                    TRANSITIVE_DEPS=$(grep -c "\\\\--- " dependency-tree.txt || echo "0")
                    OUTDATED_DEPS=$(grep -c "newer version" outdated-dependencies.txt || echo "0")
                    
                    # Generate dependency summary report
                    echo "{" > dependency-summary.json
                    echo "  \"direct_dependencies\": $DIRECT_DEPS," >> dependency-summary.json
                    echo "  \"transitive_dependencies\": $TRANSITIVE_DEPS," >> dependency-summary.json
                    echo "  \"outdated_dependencies\": $OUTDATED_DEPS," >> dependency-summary.json
                    echo "  \"analysis_date\": \"$(date -u +'%Y-%m-%dT%H:%M:%SZ')\"" >> dependency-summary.json
                    echo "}" >> dependency-summary.json
                '''
                
                archiveArtifacts artifacts: 'dependency-tree.txt,dependency-check-report.html,outdated-dependencies.txt,build/reports/license/**,dependency-summary.json', allowEmptyArchive: true
            }
            post {
                failure {
                    script {
                        collectFailureData('Dependency Audit', 'Dependency Analysis', 'Failed to analyze dependencies')
                    }
                }
            }
        }

        /**
         * Purpose: Compile application source code
         * Dependencies: gradle, JDK
         * Outputs: Compiled application
         * Ticket: DEVOPS-325
         */
        stage('Build') {
            steps {
                sh '''
                    # Verify gradlew permissions
                    chmod +x ./gradlew
                    
                    # Clean build with optimizations
                    ./gradlew clean build -x test \
                        --build-cache \
                        --parallel \
                        --max-workers=${JAVA_MAX_CPUS} \
                        -Dorg.gradle.caching=true \
                        -Dorg.gradle.configureondemand=true
                        
                    # Record build metadata
                    echo "{" > build-info.json
                    echo "  \"build_number\": \"${BUILD_NUMBER}\"," >> build-info.json
                    echo "  \"version\": \"${PROJECT_VERSION}\"," >> build-info.json
                    echo "  \"git_commit\": \"${GIT_COMMIT_HASH}\"," >> build-info.json
                    echo "  \"build_date\": \"$(date -u +'%Y-%m-%dT%H:%M:%SZ')\"," >> build-info.json
                    echo "  \"build_by\": \"${USER}\"," >> build-info.json
                    echo "  \"java_version\": \"$(java -version 2>&1 | head -n 1)\"," >> build-info.json
                    echo "  \"gradle_version\": \"$(./gradlew --version | grep Gradle | head -n 1)\"" >> build-info.json
                    echo "}" >> build-info.json
                '''
                
                archiveArtifacts artifacts: 'build-info.json', fingerprint: true
            }
            post {
                failure {
                    script {
                        collectFailureData('Build', 'Compilation', 'Failed to compile application')
                        
                        // Capture compilation errors for detailed analysis
                        sh '''
                            mkdir -p ${ERROR_TRACKING_DIR}/compilation
                            find . -name "*.log" -exec grep -l "error:" {} \\; | while read file; do
                                cp "$file" ${ERROR_TRACKING_DIR}/compilation/
                            done
                        '''
                        
                        archiveArtifacts artifacts: "${ERROR_TRACKING_DIR}/compilation/*", allowEmptyArchive: true
                    }
                }
                success {
                    echo "Build successful. Compiled application ready for testing."
                }
            }
        }

        /**
         * Purpose: Run automated tests and gather coverage metrics
         * Dependencies: gradle, JUnit, JaCoCo
         * Outputs: Test results and coverage reports
         * Ticket: DEVOPS-326
         */
        stage('Test & Coverage') {
            when { expression { return !params.SKIP_TESTS } }
            steps {
                sh '''
                    ./gradlew test jacocoTestReport \
                        --build-cache \
                        --parallel \
                        --max-workers=${JAVA_MAX_CPUS} \
                        -Dtest.parallelism=4 \
                        -Dtest.fork.count=4
                        
                    # Generate test summary
                    TEST_COUNT=$(find . -path "*/build/test-results/test/*.xml" -exec grep -l "<testcase" {} \\; | xargs grep -c "<testcase" 2>/dev/null || echo "0")
                    FAILURE_COUNT=$(find . -path "*/build/test-results/test/*.xml" -exec grep -l "<failure" {} \\; | xargs grep -c "<failure" 2>/dev/null || echo "0")
                    ERROR_COUNT=$(find . -path "*/build/test-results/test/*.xml" -exec grep -l "<error" {} \\; | xargs grep -c "<error" 2>/dev/null || echo "0")
                    SKIPPED_COUNT=$(find . -path "*/build/test-results/test/*.xml" -exec grep -l "<skipped" {} \\; | xargs grep -c "<skipped" 2>/dev/null || echo "0")
                    
                    # Get test execution time
                    TEST_TIME=$(find . -path "*/build/test-results/test/*.xml" -exec grep -l "time=" {} \\; | xargs grep "time=" | awk -F"time=" '{sum += $2} END {print sum}' 2>/dev/null || echo "0")
                    
                    # Create test summary JSON
                    echo "{" > test-summary.json
                    echo "  \"total_tests\": $TEST_COUNT," >> test-summary.json
                    echo "  \"passed_tests\": $(($TEST_COUNT - $FAILURE_COUNT - $ERROR_COUNT - $SKIPPED_COUNT))," >> test-summary.json
                    echo "  \"failed_tests\": $FAILURE_COUNT," >> test-summary.json
                    echo "  \"error_tests\": $ERROR_COUNT," >> test-summary.json
                    echo "  \"skipped_tests\": $SKIPPED_COUNT," >> test-summary.json
                    echo "  \"execution_time\": $TEST_TIME," >> test-summary.json
                    echo "  \"test_date\": \"$(date -u +'%Y-%m-%dT%H:%M:%SZ')\"" >> test-summary.json
                    echo "}" >> test-summary.json
                '''
                
                archiveArtifacts artifacts: 'test-summary.json', fingerprint: true
            }
            post {
                always {
                    junit '**/build/test-results/test/*.xml'
                    
                    jacoco(
                        execPattern: 'build/jacoco/*.exec',
                        classPattern: 'build/classes/java/main',
                        sourcePattern: 'src/main/java',
                        exclusionPattern: '**/*Test*.class'
                    )
                    
                    publishHTML(target: [
                        allowMissing: false,
                        alwaysLinkToLastBuild: true,
                        keepAll: true,
                        reportDir: 'build/reports/jacoco/test/html',
                        reportFiles: 'index.html',
                        reportName: 'Code Coverage Report'
                    ])
                    
                    script {
                        def durationMillis = System.currentTimeMillis() - env.PIPELINE_START_TIME.toLong()
                        def durationMinutes = durationMillis / 60000
                        echo "Test stage completed in ${durationMinutes.round(2)} minutes"
                    }
                }
                failure {
                    script {
                        def failedStage = currentBuild.result
                        def buildLog = currentBuild.rawBuild.getLog(1000).join('\n')
                        
                        // Extract error patterns
                        def errorPattern = ~/error:|exception:|failed:|FAILED|BUILD FAILED/
                        def errors = buildLog.readLines().findAll { it =~ errorPattern }
                        
                        echo "Tests failed in stage: ${failedStage}"
                        echo "Error summary:\n${errors.take(10).join('\n')}"
                        
                        // Enhanced error analysis and categorization
                        def errorTypes = [:]
                        errors.each { error ->
                            // Classify error types
                            if (error.contains("OutOfMemoryError")) {
                                errorTypes.putIfAbsent("Memory Issues", [])
                                errorTypes["Memory Issues"].add(error)
                            } else if (error.contains("NullPointerException")) {
                                errorTypes.putIfAbsent("Null Pointer Errors", [])
                                errorTypes["Null Pointer Errors"].add(error)
                            } else if (error.contains("Connection")) {
                                errorTypes.putIfAbsent("Connection Issues", [])
                                errorTypes["Connection Issues"].add(error)
                            } else if (error.contains("Timeout")) {
                                errorTypes.putIfAbsent("Timeout Issues", [])
                                errorTypes["Timeout Issues"].add(error)
                            } else if (error.contains("AssertionError")) {
                                errorTypes.putIfAbsent("Test Assertions", [])
                                errorTypes["Test Assertions"].add(error)
                            } else {
                                errorTypes.putIfAbsent("Other Errors", [])
                                errorTypes["Other Errors"].add(error)
                            }
                        }
                        
                        // Write detailed error report
                        def testErrorReport = [
                            'stage': 'Test & Coverage',
                            'timestamp': new Date().format("yyyy-MM-dd'T'HH:mm:ss.SSSZ"),
                            'build_number': env.BUILD_NUMBER,
                            'result': failedStage,
                            'error_count': errors.size(),
                            'error_categories': [:],
                            'error_samples': errors.take(20)
                        ]
                        
                        errorTypes.each { type, typeErrors ->
                            testErrorReport['error_categories'][type] = typeErrors.size()
                        }
                        
                        writeJSON file: "${ERROR_TRACKING_DIR}/test-errors.json", json: testErrorReport, pretty: 4
                        archiveArtifacts artifacts: "${ERROR_TRACKING_DIR}/test-errors.json", fingerprint: true
                        
                        collectFailureData('Test & Coverage', 'Test Execution', "Tests failed with ${errors.size()} errors")
                    }
                }
                success {
                    echo "All tests passed successfully!"
                }
            }
        }

        /**
         * Purpose: Run parallel static analysis and Docker image builds
         * Dependencies: SonarQube, Docker, Gradle plugins
         * Outputs: Analysis reports and Docker image